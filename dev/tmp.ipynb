{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "from flask import Flask\n",
    "from flask_socketio import SocketIO\n",
    "from flask_cors import CORS\n",
    "import eventlet\n",
    "import time\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_port = 0\n",
    "mean = 128.33125\n",
    "std = 15.842568\n",
    "\n",
    "\n",
    "def preprocess_image(img, top, bottom, left, right): # img is a np array (captured image)\n",
    "        # Crop center 256x256 pixel array\n",
    "        cropped = img[top:bottom, left:right]\n",
    "\n",
    "        # Change to grayscale\n",
    "        gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Scale the image to (128, 128)\n",
    "        resized = cv2.resize(gray, (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "        # Scale pixel values to [-1, 1]\n",
    "        normalized = (resized - mean) / std\n",
    "\n",
    "        # Add batch size (1) and channel dimension (grayscale is 1 channel)\n",
    "        processed_image = np.expand_dims(normalized, axis=(0, -1))  # Shape: (1, 128, 128, 1)\n",
    "\n",
    "        return processed_image\n",
    "\n",
    "\n",
    "def main():\n",
    "    cam = cv2.VideoCapture(cam_port)\n",
    "\n",
    "    modelPath = '../models/COSC307_limited_data_CNN2.keras'\n",
    "\n",
    "    # Load the trained Keras model\n",
    "    model = load_model(modelPath)  # Replace with the path to your model file\n",
    "\n",
    "    valid, frame = cam.read()\n",
    "\n",
    "    frameSize = frame.shape\n",
    "    x = frameSize[1]\n",
    "    y = frameSize[0]\n",
    "\n",
    "    left = int((x - 256) / 2)\n",
    "    right = left + 256\n",
    "    top = int((y - 256) / 2)\n",
    "    bottom = top + 256\n",
    "\n",
    "\n",
    "    start_point = (left, top)    # top left corner of box\n",
    "    end_point = (right, bottom)      # bottom right corner of box\n",
    "    color = (0, 0, 255)         # red (B,G,R)\n",
    "    thickness = 2\n",
    "\n",
    "    counter = 0\n",
    "    while True:\n",
    "\n",
    "        valid, frame = cam.read()   # frame holds the image object (np array)\n",
    "\n",
    "        # rectangle is 256x256\n",
    "        rectangleOverlay = cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "        cv2.imwrite(\"../image_assets/frameRect.png\", rectangleOverlay)\n",
    "\n",
    "        cv2.imshow(\"Current Frame\", rectangleOverlay)\n",
    "\n",
    "        if counter >= 5:\n",
    "            counter = 0\n",
    "\n",
    "            processed_image = preprocess_image(frame, top, bottom, left, right)\n",
    "\n",
    "            # Make a prediction\n",
    "            prediction = model.predict(processed_image, batch_size=1)\n",
    "\n",
    "            letters = ['P','Y','R','O','V']\n",
    "            maxIndex = prediction[0].argmax()\n",
    "\n",
    "            print(f\"Most Likely:  {letters[maxIndex]}, {int(prediction[0][maxIndex] * 100)}% chance\")\n",
    "        \n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "from flask import Flask\n",
    "from flask_socketio import SocketIO\n",
    "from flask_cors import CORS\n",
    "from gevent import monkey\n",
    "import time\n",
    "import base64\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app,resources={r\"/*\":{\"origins\":\"*\"}})\n",
    "socketio = SocketIO(app, cors_allowed_origins=\"*\")  # Allow any frontend to connect\n",
    "\n",
    "send_data_flag = True\n",
    "\n",
    "cam_port = 0\n",
    "mean = 128.33125\n",
    "std = 15.842568\n",
    "\n",
    "\n",
    "def preprocess_image(img, top, bottom, left, right): # img is a np array (captured image)\n",
    "        # Crop center 256x256 pixel array\n",
    "        cropped = img[top:bottom, left:right]\n",
    "\n",
    "        # Change to grayscale\n",
    "        gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Scale the image to (128, 128)\n",
    "        resized = cv2.resize(gray, (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "        # Scale pixel values to [-1, 1]\n",
    "        normalized = (resized - mean) / std\n",
    "\n",
    "        # Add batch size (1) and channel dimension (grayscale is 1 channel)\n",
    "        processed_image = np.expand_dims(normalized, axis=(0, -1))  # Shape: (1, 128, 128, 1)\n",
    "\n",
    "        return processed_image\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    _, buffer = cv2.imencode('.png', image)  # Encode as PNG\n",
    "    byte_image = buffer.tobytes()  # Convert to byte array\n",
    "    encoded_image = base64.b64encode(byte_image).decode('utf-8')  # Base64 encode\n",
    "    return encoded_image\n",
    "\n",
    "\n",
    "def send_data():\n",
    "    cam = cv2.VideoCapture(cam_port)\n",
    "\n",
    "    modelPath = '../models/COSC307_limited_data_CNN2.keras'\n",
    "\n",
    "    # Load the trained Keras model\n",
    "    model = load_model(modelPath)  # Replace with the path to your model file\n",
    "\n",
    "    valid, frame = cam.read()\n",
    "\n",
    "    frameSize = frame.shape\n",
    "    x = frameSize[1]\n",
    "    y = frameSize[0]\n",
    "\n",
    "    left = int((x - 256) / 2)\n",
    "    right = left + 256\n",
    "    top = int((y - 256) / 2)\n",
    "    bottom = top + 256\n",
    "\n",
    "\n",
    "    start_point = (left, top)    # top left corner of box\n",
    "    end_point = (right, bottom)      # bottom right corner of box\n",
    "    color = (0, 0, 255)         # red (B,G,R)\n",
    "    thickness = 2\n",
    "\n",
    "    counter = 0\n",
    "    while send_data_flag:\n",
    "\n",
    "        valid, frame = cam.read()   # frame holds the image object (np array)\n",
    "\n",
    "        # rectangle is 256x256\n",
    "        rectangleOverlay = cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "        cv2.imwrite(\"../image_assets/frameRect.png\", rectangleOverlay)\n",
    "\n",
    "        # cv2.imshow(\"Current Frame\", rectangleOverlay)\n",
    "\n",
    "        if counter >= 5:\n",
    "            counter = 0\n",
    "\n",
    "            processed_image = preprocess_image(frame, top, bottom, left, right)\n",
    "\n",
    "            # Make a prediction\n",
    "            prediction = model.predict(processed_image, batch_size=1)\n",
    "\n",
    "            letters = ['P','Y','R','O','V']\n",
    "            maxIndex = prediction[0].argmax()\n",
    "\n",
    "            print(f\"Most Likely:  {letters[maxIndex]}, {int(prediction[0][maxIndex] * 100)}% chance\")\n",
    "        \n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        # socketio.emit('server_event', {'data': 'Hello from Flask! ' + str(i)})\n",
    "\n",
    "        encoded_image = encode_image_to_base64(rectangleOverlay)\n",
    "\n",
    "        print(f\"Encoded image length: {len(encoded_image)}\")\n",
    "        # print(f\"First 100 chars of encoded image: {encoded_image[:100]}\")\n",
    "        \n",
    "        socketio.emit('receive_data', {'image': encoded_image, 'data': 'Hello from Flask!'})\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "@socketio.on('connect')\n",
    "def handle_connect():\n",
    "    print(\"Client connected\")\n",
    "    socketio.start_background_task(send_data)\n",
    "    global send_data_flag\n",
    "    send_data_flag = True\n",
    "\n",
    "\n",
    "@socketio.on('disconnect')\n",
    "def handle_disconnect():\n",
    "    global send_data_flag\n",
    "    print('Client Disconnected')\n",
    "    send_data_flag = False\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    monkey.patch_all()\n",
    "\n",
    "    socketio.run(app, port=5001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later reference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import cv2\n",
    "\n",
    "def capture_video(cam_port):\n",
    "    cam = cv2.VideoCapture(cam_port)\n",
    "    while True:\n",
    "        valid, frame = cam.read()\n",
    "        if not valid:\n",
    "            break\n",
    "        # Process your frame\n",
    "    cam.release()\n",
    "\n",
    "# In your `send_data` function, run the video capture in a separate thread\n",
    "threading.Thread(target=capture_video, args=(0,)).start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".car_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
