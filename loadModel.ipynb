{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 14,
>>>>>>> 5816799cd16d8a9f84da17768741c0ca1b7eb5c2
   "id": "6ef8ba20-dd1e-49db-aeaf-f374a5505d1d",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
=======
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image, ImageEnhance\n",
>>>>>>> 5816799cd16d8a9f84da17768741c0ca1b7eb5c2
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "id": "248c853f-97a9-4bf1-9e1c-d9dc80081933",
   "metadata": {},
=======
   "execution_count": 10,
   "id": "248c853f-97a9-4bf1-9e1c-d9dc80081933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model config file\n",
    "cwd = os.getcwd() # current directory you're working in\n",
    "# print(cwd)\n",
    "# print(f\"{cwd}/COSC307_Final_CNN.keras\")\n",
    "model = keras.models.load_model(f\"{cwd}/COSC307_Final_CNN.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a61ecd",
   "metadata": {},
   "source": [
    "This section below is for image manipulation to increase contrast and decrease brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7766b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"image_input/image_assets/saveFrame256.png\"\n",
    "\n",
    "img = Image.open(path)\n",
    "recolorer = ImageEnhance.Contrast(img)\n",
    "contrastImg = recolorer.enhance(2)\n",
    "brighten = ImageEnhance.Brightness(contrastImg)\n",
    "brightImg = brighten.enhance(0.5)\n",
    "brightImg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7d81adc-6e8f-4776-b10e-30b6972ebf28",
   "metadata": {},
>>>>>>> 5816799cd16d8a9f84da17768741c0ca1b7eb5c2
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\maden\\COSC307\n"
=======
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
>>>>>>> 5816799cd16d8a9f84da17768741c0ca1b7eb5c2
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Load model config file\n",
    "cwd = os.getcwd() # current directory you're working in\n",
    "model = keras.models.load_model(f\"{cwd}/COSC307_Final_CNN.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d81adc-6e8f-4776-b10e-30b6972ebf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For passing input to the model\n",
    "\n",
=======
    "# For passing input to the model\n",
    "\n",
    "path = \"image_input/image_assets/B_test.jpg\"\n",
    "\n",
>>>>>>> 5816799cd16d8a9f84da17768741c0ca1b7eb5c2
    "# This will help get your images into PIL format\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/load_img#returns\n",
    "img = tf.keras.utils.load_img(\n",
    "    path, # TODO: replace with path to image in image_input\n",
    "    color_mode='grayscale',\n",
    "    target_size=(256, 256),\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")\n",
    "\n",
    "input_arr = keras.utils.img_to_array(img) / 255.0 # Model expects normalized input\n",
<<<<<<< HEAD
    "input_arr = np.array([input_arr])\n",
    "input_tensor = tf.convert_to_tensor(input_arr, dtype=tf.float32)\n",
    "input_tensor = tf.expand_dims(input_tensor, axis=0) # add the batch dimension to the tensor\n",
=======
    "input_tensor = tf.expand_dims(input_arr, axis=0)\n",
    "# input_arr = np.array([input_arr])\n",
    "# input_tensor = tf.convert_to_tensor(input_arr, dtype=tf.float32)\n",
    "# input_tensor = tf.expand_dims(input_tensor, axis=0) # add the batch dimension to the tensor\n",
>>>>>>> 5816799cd16d8a9f84da17768741c0ca1b7eb5c2
    "\n",
    "predictions = model.predict(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e0522-7b48-4024-a3db-3c58b27c8f09",
   "metadata": {},
<<<<<<< HEAD
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "[7.45651544e-12 1.00000000e+00 1.82225097e-27 3.69859681e-14\n",
      " 5.78907020e-08 8.84765512e-16 1.14160400e-24 2.55173177e-36\n",
      " 1.46458515e-24 0.00000000e+00 9.45063253e-24 1.03832806e-25\n",
      " 5.62301075e-16 1.62340759e-23 9.17935462e-23 0.00000000e+00\n",
      " 0.00000000e+00 2.71630014e-24 9.08118317e-36 1.05601936e-26\n",
      " 1.88416923e-24 9.93390187e-35 2.95526680e-28 2.79182466e-30\n",
      " 3.65042151e-36 7.23980905e-31 0.00000000e+00 6.93165619e-25\n",
      " 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "values = ['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "\n",
    "predValues = dict(map(lambda i,j : (i,j), predictions[0], values))\n",
    "\n",
    "command = predValues[max(predictions[0])]\n",
    "\n",
    "print(command)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7125dbe1",
   "metadata": {},
>>>>>>> 5816799cd16d8a9f84da17768741c0ca1b7eb5c2
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3 (ipykernel)",
=======
   "display_name": "car_venv",
>>>>>>> 5816799cd16d8a9f84da17768741c0ca1b7eb5c2
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
