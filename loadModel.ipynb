{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef8ba20-dd1e-49db-aeaf-f374a5505d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248c853f-97a9-4bf1-9e1c-d9dc80081933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model config file\n",
    "cwd = os.getcwd() # current directory you're working in\n",
    "# print(cwd)\n",
    "# print(f\"{cwd}/COSC307_Final_CNN.keras\")\n",
    "model = keras.models.load_model(f\"{cwd}/COSC307_Final_CNN.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d81adc-6e8f-4776-b10e-30b6972ebf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "# For passing input to the model\n",
    "\n",
    "path = \"image_input/image_assets/saveFrame256.png\"\n",
    "\n",
    "img = Image.open(path)\n",
    "img.show()\n",
    "\n",
    "# This will help get your images into PIL format\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/load_img#returns\n",
    "img = tf.keras.utils.load_img(\n",
    "    path, # TODO: replace with path to image in image_input\n",
    "    color_mode='grayscale',\n",
    "    target_size=(256, 256),\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")\n",
    "\n",
    "input_arr = keras.utils.img_to_array(img) / 255.0 # Model expects normalized input\n",
    "input_tensor = tf.expand_dims(input_arr, axis=0)\n",
    "# input_arr = np.array([input_arr])\n",
    "# input_tensor = tf.convert_to_tensor(input_arr, dtype=tf.float32)\n",
    "# input_tensor = tf.expand_dims(input_tensor, axis=0) # add the batch dimension to the tensor\n",
    "\n",
    "predictions = model.predict(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b18e0522-7b48-4024-a3db-3c58b27c8f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "[2.44866037e-19 3.34485447e-19 7.79706118e-29 3.65881228e-16\n",
      " 2.73597399e-12 6.89242443e-05 7.88350885e-10 9.43059758e-13\n",
      " 2.55352273e-08 9.78249955e-05 1.48590581e-04 5.01821328e-12\n",
      " 1.02323365e-10 2.99898062e-09 6.26666687e-14 1.84831615e-13\n",
      " 2.83593543e-13 2.14966134e-09 5.03566795e-18 7.93006719e-13\n",
      " 2.20300264e-10 3.23802378e-05 9.93203402e-01 3.08170503e-12\n",
      " 1.14774210e-07 3.87234326e-15 3.16710043e-06 2.96584564e-24\n",
      " 6.44550193e-03]\n"
     ]
    }
   ],
   "source": [
    "values = ['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "\n",
    "# values = ['A','C','L','P','Y']\n",
    "# indexes = [0, 2, 12, 17, 27]\n",
    "# keys = []\n",
    "# for i in indexes:\n",
    "#     keys.append(predictions[0][i])\n",
    "\n",
    "command = values[np.argmax(predictions[0])]\n",
    "print(command)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7125dbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
