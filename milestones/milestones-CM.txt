1 hr (11:20-12:20) 9/30/24 -    Researching CNN models in lab with Porter. This included specific research into how hidden 
                                layers and what good attributes may be for them. 
4 hr (4:30-8:30) 9/30/24   -    Programmed image input and basic manipulation. This time also included research into OpenCV 
                                and Pillow for image manipulation in Python as well as setting up my environment for python coding on Jupyter.

My section of this challenge is found in the Image-Capture branch, under the image_input directory. My compilable task is "takePicture.ipynb".

Rubric: (40 total)
+20 points: Car functions with reasonable accuracy, responding to hand gestures in real time
+10 points: Fully functional web app displays live information
+10 points: Clear project documentation and formatting / commenting
+5 points: Even distribution of time, matching up to the expected time for this project
+5 points: Program takes frequent images and doesn't seem overly slow

Report:
    This challenge went well for me. The vast majority of it was spend doing research and learning my tools, especially 
    OpenCV. OpenCV is going to be the primary way that we gather data from user interaction, so it's very important for 
    the project as a whole. In today's challenge, I actually wrote code that will function as the entire input section 
    for our data. All I need to change in it is to send the images to a web framework instead of a local file. 